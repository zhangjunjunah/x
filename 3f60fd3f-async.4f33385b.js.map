{"version":3,"sources":["docs/react/model-use-openai.en-US.md?type=text"],"sourcesContent":["\n  import '/home/runner/work/x/x/docs/react/model-use-openai.en-US.md?watch=parent';\n  export const texts = [{\"value\":\"This guide will explain how to integrate OpenAI's model service into an application built using Ant Design X.\",\"paraId\":0},{\"value\":\"This is equivalent to integrating with a model inference service compatible with OpenAI. For reference, see \",\"paraId\":1,\"tocIndex\":0},{\"value\":\"Model Integration - Qwen\",\"paraId\":2,\"tocIndex\":0},{\"value\":\".\",\"paraId\":1,\"tocIndex\":0},{\"value\":\"Typically, \",\"paraId\":3,\"tocIndex\":1},{\"value\":\"openai-node\",\"paraId\":3,\"tocIndex\":1},{\"value\":\" is used in a Node environment. If used in a browser environment, the \",\"paraId\":3,\"tocIndex\":1},{\"value\":\"dangerouslyAllowBrowser\",\"paraId\":3,\"tocIndex\":1},{\"value\":\" option must be enabled.\",\"paraId\":3,\"tocIndex\":1},{\"value\":\"Note: \",\"paraId\":4,\"tocIndex\":1},{\"value\":\"dangerouslyAllowBrowser\",\"paraId\":4,\"tocIndex\":1},{\"value\":\" poses a security risk. For more details, refer to the official \",\"paraId\":4,\"tocIndex\":1},{\"value\":\"documentation\",\"paraId\":4,\"tocIndex\":1},{\"value\":\".\",\"paraId\":4,\"tocIndex\":1},{\"value\":\"import { useXAgent, useXChat, Sender, Bubble } from '@ant-design/x';\\nimport OpenAI from 'openai';\\nimport React from 'react';\\n\\nconst client = new OpenAI({\\n  apiKey: process.env['OPENAI_API_KEY'],\\n  dangerouslyAllowBrowser: true,\\n});\\n\\nconst Demo: React.FC = () => {\\n  const [agent] = useXAgent({\\n    request: async (info, callbacks) => {\\n      const { messages, message } = info;\\n\\n      const { onSuccess, onUpdate, onError } = callbacks;\\n\\n      // current message\\n      console.log('message', message);\\n\\n      // history messages\\n      console.log('messages', messages);\\n\\n      let content: string = '';\\n\\n      try {\\n        const stream = await client.chat.completions.create({\\n          model: 'gpt-4o',\\n          // if chat context is needed, modify the array\\n          messages: [{ role: 'user', content: message }],\\n          // stream mode\\n          stream: true,\\n        });\\n\\n        for await (const chunk of stream) {\\n          content += chunk.choices[0]?.delta?.content || '';\\n\\n          onUpdate(content);\\n        }\\n\\n        onSuccess(content);\\n      } catch (error) {\\n        // handle error\\n        // onError();\\n      }\\n    },\\n  });\\n\\n  const {\\n    // use to send message\\n    onRequest,\\n    // use to render messages\\n    messages,\\n  } = useXChat({ agent });\\n\\n  const items = messages.map(({ message, id }) => ({\\n    // key is required, used to identify the message\\n    key: id,\\n    content: message,\\n  }));\\n\\n  return (\\n    <div>\\n      <Bubble.List items={items} />\\n      <Sender onSubmit={onRequest} />\\n    </div>\\n  );\\n};\\n\\nexport default Demo;\\n\",\"paraId\":5,\"tocIndex\":1}];\n  "],"names":[],"mappings":"+PAEe,6CAAA,QADN,YACA,IAAM,EAAQ,CAAC,CAAC,MAAQ,gHAAgH,OAAS,CAAC,EAAE,CAAC,MAAQ,+GAA+G,OAAS,EAAE,SAAW,CAAC,EAAE,CAAC,MAAQ,2BAA2B,OAAS,EAAE,SAAW,CAAC,EAAE,CAAC,MAAQ,IAAI,OAAS,EAAE,SAAW,CAAC,EAAE,CAAC,MAAQ,cAAc,OAAS,EAAE,SAAW,CAAC,EAAE,CAAC,MAAQ,cAAc,OAAS,EAAE,SAAW,CAAC,EAAE,CAAC,MAAQ,yEAAyE,OAAS,EAAE,SAAW,CAAC,EAAE,CAAC,MAAQ,0BAA0B,OAAS,EAAE,SAAW,CAAC,EAAE,CAAC,MAAQ,2BAA2B,OAAS,EAAE,SAAW,CAAC,EAAE,CAAC,MAAQ,SAAS,OAAS,EAAE,SAAW,CAAC,EAAE,CAAC,MAAQ,0BAA0B,OAAS,EAAE,SAAW,CAAC,EAAE,CAAC,MAAQ,mEAAmE,OAAS,EAAE,SAAW,CAAC,EAAE,CAAC,MAAQ,gBAAgB,OAAS,EAAE,SAAW,CAAC,EAAE,CAAC,MAAQ,IAAI,OAAS,EAAE,SAAW,CAAC,EAAE,CAAC,MAAQ,6lDAA6lD,OAAS,EAAE,SAAW,CAAC,EAAE"}